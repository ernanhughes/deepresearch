{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import openai\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Manages configurable parameters.\"\"\"\n",
    "    def __init__(self, directory, topic, api_key, model_name='all-MiniLM-L6-v2', llm_models=['gpt-4'], db_path='results.db'):\n",
    "        self.directory = directory\n",
    "        self.topic = topic\n",
    "        self.api_key = api_key\n",
    "        self.model_name = model_name\n",
    "        self.llm_models = llm_models if isinstance(llm_models, list) else [llm_models]\n",
    "        self.db_path = db_path\n",
    "        openai.api_key = api_key\n",
    "\n",
    "class MarkdownCleaner:\n",
    "    @staticmethod\n",
    "    def clean_markdown(md_text):\n",
    "        \"\"\"Remove Markdown syntax and extract clean text.\"\"\"\n",
    "        md_text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', md_text)  # Remove links\n",
    "        md_text = re.sub(r'#{1,6}\\s*', '', md_text)  # Remove headers\n",
    "        md_text = re.sub(r'(```.*?```|`.*?`)', '', md_text, flags=re.DOTALL)  # Remove code blocks\n",
    "        md_text = re.sub(r'\\*{1,2}|\\_{1,2}', '', md_text)  # Remove bold/italic formatting\n",
    "        md_text = re.sub(r'>\\s*', '', md_text)  # Remove blockquotes\n",
    "        md_text = re.sub(r'[-+*]\\s+', '', md_text)  # Remove bullet points\n",
    "        md_text = re.sub(r'\\d+\\.\\s+', '', md_text)  # Remove numbered lists\n",
    "        return md_text.strip()\n",
    "\n",
    "class DocumentEvaluator:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.model = SentenceTransformer(config.model_name)\n",
    "        self._initialize_database()\n",
    "    \n",
    "    def _initialize_database(self):\n",
    "        \"\"\"Initialize the database table to store results.\"\"\"\n",
    "        conn = sqlite3.connect(self.config.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS document_scores (\n",
    "                filename TEXT PRIMARY KEY,\n",
    "                relevance_score REAL,\n",
    "                correctness_score REAL,\n",
    "                final_score REAL\n",
    "            )\n",
    "        ''')\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    \n",
    "    def save_results_to_db(self, rankings):\n",
    "        \"\"\"Save ranked document results to the database.\"\"\"\n",
    "        conn = sqlite3.connect(self.config.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        for filename, relevance, correctness, final_score in rankings:\n",
    "            cursor.execute('''\n",
    "                INSERT INTO document_scores (filename, relevance_score, correctness_score, final_score)\n",
    "                VALUES (?, ?, ?, ?)\n",
    "                ON CONFLICT(filename) DO UPDATE SET\n",
    "                    relevance_score=excluded.relevance_score,\n",
    "                    correctness_score=excluded.correctness_score,\n",
    "                    final_score=excluded.final_score\n",
    "            ''', (filename, relevance, correctness, final_score))\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    \n",
    "    def load_markdown_files(self):\n",
    "        \"\"\"Load all Markdown files from a directory and extract clean text.\"\"\"\n",
    "        documents = []\n",
    "        for filename in os.listdir(self.config.directory):\n",
    "            if filename.endswith(\".md\"):\n",
    "                with open(os.path.join(self.config.directory, filename), \"r\", encoding=\"utf-8\") as file:\n",
    "                    text = file.read()\n",
    "                    clean_text = MarkdownCleaner.clean_markdown(text)\n",
    "                    documents.append((filename, clean_text))\n",
    "        return documents\n",
    "    \n",
    "    def compute_relevance(self, documents):\n",
    "        \"\"\"Compute relevance scores using embeddings.\"\"\"\n",
    "        doc_texts = [doc[1] for doc in documents]\n",
    "        doc_embeddings = self.model.encode(doc_texts)\n",
    "        topic_embedding = self.model.encode([self.config.topic])[0]  # Topic embedding\n",
    "\n",
    "        # Compute similarity\n",
    "        scores = cosine_similarity([topic_embedding], doc_embeddings)[0]\n",
    "\n",
    "        # Attach scores to documents\n",
    "        relevance_scores = {doc[0]: score for doc, score in zip(documents, scores)}\n",
    "        return relevance_scores\n",
    "    \n",
    "    def evaluate_correctness_with_llm(self, document_text):\n",
    "        \"\"\"Use multiple LLMs to evaluate correctness based on factual accuracy and logical consistency.\"\"\"\n",
    "        total_score = 0\n",
    "        for model in self.config.llm_models:\n",
    "            prompt = f\"\"\"\n",
    "            You are an expert reviewer. Evaluate the following document for correctness based on:\n",
    "            - Factual accuracy\n",
    "            - Logical consistency\n",
    "            - Clarity and grammar\n",
    "            \n",
    "            Provide a score from 1 to 10 and justify your score.\n",
    "\n",
    "            Document:\n",
    "            ```\n",
    "            {document_text}\n",
    "            ```\n",
    "            \"\"\"\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            \n",
    "            result = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "            score_match = re.search(r'Correctness Score:\\s*(\\d+)/10', result)\n",
    "            score = int(score_match.group(1)) if score_match else 5\n",
    "            total_score += score\n",
    "        \n",
    "        final_score = total_score / len(self.config.llm_models)\n",
    "        return final_score\n",
    "    \n",
    "    def rank_documents(self):\n",
    "        \"\"\"Rank documents based on relevance and correctness.\"\"\"\n",
    "        documents = self.load_markdown_files()\n",
    "        relevance_scores = self.compute_relevance(documents)\n",
    "        correctness_scores = {}\n",
    "        \n",
    "        for filename, text in documents:\n",
    "            score = self.evaluate_correctness_with_llm(text)\n",
    "            correctness_scores[filename] = score\n",
    "        \n",
    "        rankings = []\n",
    "        for filename in relevance_scores.keys():\n",
    "            relevance = relevance_scores[filename]\n",
    "            correctness = correctness_scores[filename]\n",
    "            final_score = (relevance * 5) + (correctness * 5)\n",
    "            rankings.append((filename, relevance, correctness, final_score))\n",
    "        \n",
    "        rankings.sort(key=lambda x: x[3], reverse=True)\n",
    "        self.save_results_to_db(rankings)\n",
    "        \n",
    "        df = pd.DataFrame(rankings, columns=[\"File\", \"Relevance Score\", \"Correctness Score\", \"Final Score\"])\n",
    "        import ace_tools as tools\n",
    "        tools.display_dataframe_to_user(name=\"Ranked Documents\", dataframe=df)\n",
    "\n",
    "# Example Usage\n",
    "config = Config(directory=\"path_to_markdown_files\", \n",
    "                topic=\"Artificial Intelligence and Deep Learning\", \n",
    "                api_key=\"your-api-key\", \n",
    "                llm_models=[\"gpt-4\", \"gpt-3.5-turbo\"],\n",
    "                db_path=\"results.db\")\n",
    "\n",
    "evaluator = DocumentEvaluator(config)\n",
    "evaluator.rank_documents()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
