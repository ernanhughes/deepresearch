{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Configuration Class\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.search_query = \"agent\"\n",
    "        self.max_results = 5\n",
    "        self.output_folder = \"data\"\n",
    "        self.base_url = \"http://export.arxiv.org/api/query?\"\n",
    "        self.log_db_path = \"app_logs.db\"\n",
    "        self.log_file_path = \"app.log\"\n",
    "\n",
    "    def load_from_env(self):\n",
    "        self.search_query = os.environ.get(\"SEARCH_QUERY\", self.search_query)\n",
    "        self.max_results = int(os.environ.get(\"MAX_RESULTS\", self.max_results))\n",
    "        self.output_folder = os.environ.get(\"OUTPUT_FOLDER\", self.output_folder)\n",
    "        self.base_url = os.environ.get(\"BASE_URL\", self.base_url)\n",
    "        self.log_db_path = os.environ.get(\"LOG_DB_PATH\", self.log_db_path)\n",
    "        self.log_file_path = os.environ.get(\"LOG_FILE_PATH\", self.log_file_path)\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "# Initialize Configuration\n",
    "config = Config().load_from_env()  # Load from env variables first\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app_logs.db\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sqlite3\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "# DatabaseHandler for logging\n",
    "class DatabaseHandler(logging.Handler):\n",
    "    def __init__(self, db_path):\n",
    "        super().__init__()\n",
    "        self.db_path = db_path\n",
    "        self.conn = sqlite3.connect(self.db_path)\n",
    "\n",
    "    def emit(self, record):\n",
    "        try:\n",
    "            self.conn.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS logs (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    timestamp TEXT,\n",
    "                    level TEXT,\n",
    "                    message TEXT\n",
    "                )\n",
    "            \"\"\")\n",
    "            self.conn.commit()\n",
    "            cursor = self.conn.cursor()\n",
    "            timestamp = datetime.datetime.fromtimestamp(record.created).isoformat()\n",
    "            log_entry = (timestamp, record.levelname, record.getMessage())\n",
    "            cursor.execute(\"INSERT INTO logs (timestamp, level, message) VALUES (?, ?, ?)\", log_entry)\n",
    "            self.conn.commit()\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"Error logging to database: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error in DatabaseHandler: {e}\")\n",
    "\n",
    "# Configure logging to console, file, and database\n",
    "file_handler = logging.FileHandler(config.log_file_path)\n",
    "print(config.log_db_path)\n",
    "db_handler = DatabaseHandler(config.log_db_path)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "db_handler.setFormatter(formatter)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(db_handler)\n",
    "\n",
    "\n",
    "logger.info(\"test\")\n",
    "logger.info(\"test 2\")\n",
    "logger.info(\"test 3\")\n",
    "logger.info(\"test 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "\n",
    "class DatabaseHandler(logging.Handler):\n",
    "    def __init__(self, db_path):\n",
    "        super().__init__()\n",
    "        self.db_path = db_path\n",
    "        self._initialize_db()\n",
    "\n",
    "    def _initialize_db(self):\n",
    "        \"\"\"Ensure the logs table exists.\"\"\"\n",
    "        try:\n",
    "            with sqlite3.connect(self.db_path) as conn:\n",
    "                conn.execute(\"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS logs (\n",
    "                        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                        timestamp TEXT,\n",
    "                        level TEXT,\n",
    "                        message TEXT\n",
    "                    )\n",
    "                \"\"\")\n",
    "                conn.commit()\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"Error initializing database: {e}\")\n",
    "\n",
    "    def emit(self, record):\n",
    "        \"\"\"Insert log record into the database.\"\"\"\n",
    "        try:\n",
    "            with sqlite3.connect(self.db_path) as conn:\n",
    "                cursor = conn.cursor()\n",
    "                timestamp = datetime.datetime.fromtimestamp(record.created).isoformat()\n",
    "                log_entry = (timestamp, record.levelname, record.getMessage())\n",
    "                cursor.execute(\"INSERT INTO logs (timestamp, level, message) VALUES (?, ?, ?)\", log_entry)\n",
    "                conn.commit()\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"Database error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error in DatabaseHandler: {e}\")\n",
    "\n",
    "# Ensure Config class is instantiated before using it\n",
    "config = Config().load_from_env()\n",
    "\n",
    "# Ensure log directory exists\n",
    "if not os.path.exists(config.output_folder):\n",
    "    os.makedirs(config.output_folder)\n",
    "\n",
    "# Set up logging\n",
    "log_file_path = os.path.join(config.output_folder, \"app.log\")\n",
    "\n",
    "file_handler = logging.FileHandler(log_file_path)\n",
    "db_handler = DatabaseHandler(config.log_db_path)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "db_handler.setFormatter(formatter)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(db_handler)\n",
    "\n",
    "# Test logging\n",
    "logger.info(\"test\")\n",
    "logger.info(\"test 2\")\n",
    "logger.info(\"test 3\")\n",
    "logger.info(\"test 4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Config class (ensure it's properly loaded before use)\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.search_query = \"agent\"\n",
    "        self.max_results = 50\n",
    "        self.output_folder = \"data\"\n",
    "        self.base_url = \"http://export.arxiv.org/api/query?\"\n",
    "        self.log_db_path = \"app_logs.db\"\n",
    "\n",
    "    def load_from_env(self):\n",
    "        self.search_query = os.environ.get(\"SEARCH_QUERY\", self.search_query)\n",
    "        self.max_results = int(os.environ.get(\"MAX_RESULTS\", self.max_results))\n",
    "        self.output_folder = os.environ.get(\"OUTPUT_FOLDER\", self.output_folder)\n",
    "        self.base_url = os.environ.get(\"BASE_URL\", self.base_url)\n",
    "        self.log_db_path = os.environ.get(\"LOG_DB_PATH\", self.log_db_path)\n",
    "        return self\n",
    "\n",
    "\n",
    "# DatabaseHandler for SQLite logging\n",
    "import sqlite3\n",
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "\n",
    "class DatabaseHandler(logging.Handler):\n",
    "    def __init__(self, db_path):\n",
    "        super().__init__()\n",
    "        self.db_path = db_path\n",
    "        self._initialize_db()\n",
    "\n",
    "    def _initialize_db(self):\n",
    "        \"\"\"Ensures the logs table exists in SQLite.\"\"\"\n",
    "        try:\n",
    "            with sqlite3.connect(self.db_path, check_same_thread=False) as conn:\n",
    "                cursor = conn.cursor()\n",
    "                cursor.execute(\"\"\"\n",
    "                    CREATE TABLE IF NOT EXISTS logs (\n",
    "                        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                        timestamp TEXT NOT NULL,\n",
    "                        level TEXT NOT NULL,\n",
    "                        message TEXT NOT NULL\n",
    "                    )\n",
    "                \"\"\")  # Executes the statement separately\n",
    "                conn.commit()\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"Error initializing database: {e}\")\n",
    "\n",
    "    def emit(self, record):\n",
    "        \"\"\"Inserts a log record into the database safely.\"\"\"\n",
    "        try:\n",
    "            with sqlite3.connect(self.db_path, check_same_thread=False) as conn:\n",
    "                cursor = conn.cursor()\n",
    "                timestamp = datetime.datetime.fromtimestamp(record.created).isoformat()\n",
    "                log_entry = (timestamp, record.levelname, record.getMessage())\n",
    "                cursor.execute(\n",
    "                    \"INSERT INTO logs (timestamp, level, message) VALUES (?, ?, ?)\",\n",
    "                    log_entry\n",
    "                )  # Ensuring a single statement is executed at a time\n",
    "                conn.commit()\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"Database error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error in DatabaseHandler: {e}\")\n",
    "\n",
    "\n",
    "# Ensure Config is initialized before logging\n",
    "config = Config().load_from_env()\n",
    "\n",
    "# Ensure log directory exists\n",
    "if not os.path.exists(config.output_folder):\n",
    "    os.makedirs(config.output_folder)\n",
    "\n",
    "# Set up logging\n",
    "log_file_path = os.path.join(config.output_folder, \"app.log\")\n",
    "\n",
    "file_handler = logging.FileHandler(log_file_path)\n",
    "db_handler = DatabaseHandler(config.log_db_path)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "db_handler.setFormatter(formatter)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(db_handler)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import tool\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "from typing import Optional, List, Tuple\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "import hashlib\n",
    "import re\n",
    "import sqlite3\n",
    "\n",
    "@tool\n",
    "def fetch_arxiv_papers(search_query: str = None, max_results: Optional[int] = None) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Searches arXiv for research papers on a topic and saves the papers to a folder\n",
    "    Args:\n",
    "        search_query: the topic to search for\n",
    "        max_results: max results to return\n",
    "    \"\"\"\n",
    "\n",
    "    search_query = search_query or config.search_query\n",
    "    max_results = max_results or config.max_results\n",
    "\n",
    "    db_name = f\"{search_query}.db\"\n",
    "    conn = None\n",
    "\n",
    "    try:\n",
    "        Path(config.output_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        conn = sqlite3.connect(db_name)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS papers (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                search_query TEXT,\n",
    "                title TEXT UNIQUE,\n",
    "                pdf_link TEXT,\n",
    "                file_path TEXT,\n",
    "                file_hash TEXT,\n",
    "                file_content BLOB\n",
    "            )\n",
    "        \"\"\")\n",
    "        conn.commit()\n",
    "\n",
    "        logger.info(f\"Searching for papers on '{search_query}'...\")\n",
    "        response_text = _fetch_arxiv_metadata(search_query, max_results)\n",
    "        papers = _parse_paper_links(response_text)\n",
    "\n",
    "        logger.info(f\"Found {len(papers)} papers. Starting download...\")\n",
    "        downloaded_count = 0\n",
    "        for title, pdf_link, file_name in papers:\n",
    "            try:\n",
    "                file_path = _download_paper(title, pdf_link, file_name, config.output_folder)\n",
    "                if file_path:\n",
    "                    file_hash = compute_file_hash(file_path)\n",
    "\n",
    "                    with open(file_path, \"rb\") as f:\n",
    "                        file_content = f.read()\n",
    "\n",
    "                    cursor.execute(\"\"\"\n",
    "                        INSERT OR IGNORE INTO papers (search_query, title, pdf_link, file_path, file_hash, file_content)\n",
    "                        VALUES (?, ?, ?, ?, ?, ?)\n",
    "                    \"\"\", (search_query, title, pdf_link, file_path, file_hash, file_content))\n",
    "                    conn.commit()\n",
    "\n",
    "                    downloaded_count += 1\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    logger.warning(f\"Skipping database entry for {title} due to download failure.\")\n",
    "\n",
    "            except sqlite3.Error as e:\n",
    "                logger.error(f\"Database error: {e}\")\n",
    "                if conn:\n",
    "                    conn.rollback()\n",
    "                return []\n",
    "            except Exception as e:\n",
    "                logger.exception(f\"An unexpected error occurred during processing of {title}: \")\n",
    "                if conn:\n",
    "                    conn.rollback()\n",
    "                return []\n",
    "\n",
    "        logger.info(f\"Download and database update complete! {downloaded_count} papers processed.\")\n",
    "        return papers\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        logger.error(f\"Database connection error: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        logger.exception(\"A general error occurred:\")\n",
    "        return []\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "\n",
    "def sanitize_filename(title: str) -> str:\n",
    "    return re.sub(r\"[^\\w\\s-]\", \"\", title).strip().replace(\" \", \"_\")\n",
    "\n",
    "\n",
    "def _get_filename_from_url(url: str) -> str:\n",
    "    parsed_url = urlparse(url)\n",
    "    return os.path.basename(parsed_url.path).split(\".\")[0]\n",
    "\n",
    "\n",
    "def compute_file_hash(file_path: str, algorithm: str = \"sha256\") -> str:\n",
    "    hash_func = hashlib.new(algorithm)\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        for chunk in iter(lambda: file.read(8192), b\"\"):\n",
    "            hash_func.update(chunk)\n",
    "    return hash_func.hexdigest()\n",
    "\n",
    "\n",
    "def _fetch_arxiv_metadata(search_query: str, max_results: int) -> str:\n",
    "    url = f\"{config.base_url}search_query=all:{search_query}&start=0&max_results={max_results}\"\n",
    "    logger.info(f\"Fetching metadata from: {url}\")\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def _parse_paper_links(response_text: str) -> List[Tuple[str, str]]:\n",
    "    root = ET.fromstring(response_text)\n",
    "    papers = []\n",
    "    for entry in root.findall(\"{http://www.w3.org/2005/Atom}entry\"):\n",
    "        pdf_link = None\n",
    "        title = None\n",
    "        for link in entry.findall(\"{http://www.w3.org/2005/Atom}link\"):\n",
    "            if link.attrib.get(\"title\") == \"pdf\":\n",
    "                pdf_link = link.attrib[\"href\"] + \".pdf\"\n",
    "                file_name = os.path.basename(urlparse(pdf_link).path)\n",
    "                title = entry.find(\"{http://www.w3.org/2005/Atom}title\").text\n",
    "                break\n",
    "\n",
    "        if pdf_link and title:\n",
    "            papers.append((title, pdf_link, file_name))\n",
    "            logger.info(f\"Found paper: {title}, pdf: {pdf_link}\")\n",
    "\n",
    "    return papers\n",
    "\n",
    "def _download_paper(title, pdf_link, file_name, output_folder):\n",
    "    \"\"\"Downloads a single paper PDF.\"\"\"\n",
    "    # Create a safe filename\n",
    "    safe_title = sanitize_filename(title)\n",
    "    filename = os.path.join(output_folder, f\"{file_name}\")\n",
    "    response = requests.get(pdf_link, stream=True)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Write the PDF to the specified folder\n",
    "    with open(filename, \"wb\") as file:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            file.write(chunk)\n",
    "    logger.info(f\"Downloaded: {title}: {file_name}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\logging\\__init__.py\", line 1113, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeEncodeError: 'charmap' codec can't encode character '\\u03bb' in position 151: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ernan\\AppData\\Local\\Temp\\ipykernel_8160\\4176178057.py\", line 1, in <module>\n",
      "    result = fetch_arxiv_papers(search_query=\"Cellular Automata\")\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\smolagents\\tools.py\", line 191, in __call__\n",
      "    outputs = self.forward(*args, **kwargs)\n",
      "  File \"C:\\Users\\ernan\\AppData\\Local\\Temp\\ipykernel_8160\\2185969259.py\", line 52, in fetch_arxiv_papers\n",
      "    papers = _parse_paper_links(response_text)\n",
      "  File \"C:\\Users\\ernan\\AppData\\Local\\Temp\\ipykernel_8160\\2185969259.py\", line 141, in _parse_paper_links\n",
      "    logger.info(f\"Found paper: {title}, pdf: {pdf_link}\")\n",
      "Message: 'Found paper: A New Parameter $F$ to Classify Cellular Automata Rule Table Space and a\\n  Phase Diagram in $λ-F$ Plane, pdf: http://arxiv.org/pdf/nlin/0211015v1.pdf'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\logging\\__init__.py\", line 1113, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeEncodeError: 'charmap' codec can't encode character '\\u03bb' in position 151: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ernan\\AppData\\Local\\Temp\\ipykernel_8160\\4176178057.py\", line 1, in <module>\n",
      "    result = fetch_arxiv_papers(search_query=\"Cellular Automata\")\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\smolagents\\tools.py\", line 191, in __call__\n",
      "    outputs = self.forward(*args, **kwargs)\n",
      "  File \"C:\\Users\\ernan\\AppData\\Local\\Temp\\ipykernel_8160\\2185969259.py\", line 52, in fetch_arxiv_papers\n",
      "    papers = _parse_paper_links(response_text)\n",
      "  File \"C:\\Users\\ernan\\AppData\\Local\\Temp\\ipykernel_8160\\2185969259.py\", line 141, in _parse_paper_links\n",
      "    logger.info(f\"Found paper: {title}, pdf: {pdf_link}\")\n",
      "Message: 'Found paper: A New Parameter $F$ to Classify Cellular Automata Rule Table Space and a\\n  Phase Diagram in $λ-F$ Plane, pdf: http://arxiv.org/pdf/nlin/0211015v1.pdf'\n",
      "Arguments: ()\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\logging\\__init__.py\", line 1113, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeEncodeError: 'charmap' codec can't encode character '\\u03bb' in position 151: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ernan\\AppData\\Local\\Temp\\ipykernel_8160\\4176178057.py\", line 1, in <module>\n",
      "    result = fetch_arxiv_papers(search_query=\"Cellular Automata\")\n",
      "  File \"d:\\projects\\deepresearch\\venv\\Lib\\site-packages\\smolagents\\tools.py\", line 191, in __call__\n",
      "    outputs = self.forward(*args, **kwargs)\n",
      "  File \"C:\\Users\\ernan\\AppData\\Local\\Temp\\ipykernel_8160\\2185969259.py\", line 52, in fetch_arxiv_papers\n",
      "    papers = _parse_paper_links(response_text)\n",
      "  File \"C:\\Users\\ernan\\AppData\\Local\\Temp\\ipykernel_8160\\2185969259.py\", line 141, in _parse_paper_links\n",
      "    logger.info(f\"Found paper: {title}, pdf: {pdf_link}\")\n",
      "Message: 'Found paper: A New Parameter $F$ to Classify Cellular Automata Rule Table Space and a\\n  Phase Diagram in $λ-F$ Plane, pdf: http://arxiv.org/pdf/nlin/0211015v1.pdf'\n",
      "Arguments: ()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: Cellular automata on a $G$-set\n",
      "Downloaded: Cellular Automata, PDEs, and Pattern Formation\n",
      "Downloaded: Randomized Cellular Automata\n",
      "Downloaded: About the embedding of one dimensional cellular automata into hyperbolic\n",
      "  cellular automata\n",
      "Downloaded: Two Cellular Automata for the 3x+1 Map\n",
      "Downloaded: Cellular Automata: Wolfram's Metaphors for Complex Systems\n",
      "Downloaded: New Cellular Automata associated with the Schroedinger Discrete Spectral\n",
      "  Problem\n",
      "Downloaded: On Reversible Cellular Automata with Triplet Local Rules\n",
      "Downloaded: Non-Uniform Cellular Automata: classes, dynamics, and decidability\n",
      "Downloaded: Unraveling simplicity in elementary cellular automata\n",
      "Downloaded: A Linear Acceleration Theorem for 2D Cellular Automata on all Complete\n",
      "  Neighborhoods\n",
      "Downloaded: Phase Space Invertible Asynchronous Cellular Automata\n",
      "Downloaded: On the decomposition of stochastic cellular automata\n",
      "Downloaded: Eventually Number-Conserving Cellular Automata\n",
      "Downloaded: CAX: Cellular Automata Accelerated in JAX\n",
      "Downloaded: Expressiveness of Elementary Cellular Automata\n",
      "Downloaded: A Note on Elementary Cellular Automata Classification\n",
      "Downloaded: Gauge-invariance in cellular automata\n",
      "Downloaded: Cellular Automata on Quantum Annealing Systems\n",
      "Downloaded: Cellular Automata and Discrete Geometry\n",
      "Downloaded: Quantum Circuits for Elementary Cellular Automata\n",
      "Downloaded: Quantum Cellular Automata from Lattice Field Theories\n",
      "Downloaded: Enumeration of number-conserving cellular automata rules with two inputs\n",
      "Downloaded: Issues on drawing the State Transition Diagram for arbitrary Cellular\n",
      "  Automata\n",
      "Downloaded: A guided tour of asynchronous cellular automata\n",
      "Downloaded: Regional Control of Probabilistic Cellular Automata\n",
      "Downloaded: Cellular automata on regular rooted trees\n",
      "Downloaded: A natural class of cellular automata containing fractional\n",
      "  multiplication automata, Rule 30, and others\n",
      "Downloaded: Bulking II: Classifications of Cellular Automata\n",
      "Downloaded: Classification of Cellular Automata based on the Hamming distance\n",
      "Downloaded: On generalization of reversible second-order cellular automata\n",
      "Downloaded: Triangular Automata: The 256 Elementary Cellular Automata of the 2D\n",
      "  Plane\n",
      "Downloaded: Evolution of Spots and Stripes in Cellular Automata\n",
      "Downloaded: On complex dynamics from reversible cellular automata\n",
      "Downloaded: Unitarity in one dimensional nonlinear quantum cellular automata\n",
      "Downloaded: Introduction to Quantum Cellular Automata\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "result = fetch_arxiv_papers(search_query=\"Cellular Automata\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
